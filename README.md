# ðŸ§  Deep Reinforcement Learning for Personalized Radiotherapy Beam Orientation

This repository contains the code and experiments for my work on **patient-specific Beam Orientation Optimization (BOO)** in head-and-neck radiotherapy using **Deep Q-Learning (DQN)**. The agent learns to select clinically meaningful gantry angles directly from voxel-level anatomy, **without** repeated Monte Carlo dose simulations.

> **TL;DR:** Given CT + anatomical masks, this system proposes 5 optimal beam angles in **<1 second** inference per patient after training, improving PTV coverage vs. equiangular baselines.


---

## ðŸ”— Quick Navigation
- ðŸ” Overview & Motivation
- ðŸ“ˆ Results (100 Patients)
- ðŸ“‚ Repository Structure
- âš™ï¸ Installation
- â–¶ï¸ Evaluation
- ðŸ‹ï¸ Training
- ðŸ§¬ Model Summary
- ðŸ”® Future Work
- ðŸ“„ Citation
- ðŸ™ Acknowledgements


---

## ðŸ“Œ Overview / Problem

Selecting clinically optimal beam orientations is crucial in radiotherapy.  
Conventional BOO methods:

- âŒ Not personalized to anatomy
- âŒ Computationally infeasible at large search spaces
- âŒ Insensitive to voxel-level geometry
- âŒ Require repeated full dose simulations

---

## ðŸš€ Core Idea

We formulate BOO as a **sequential decision-making problem** and train a Deep Q-Network to:

- Extract **voxel-level anatomical structure** from CT + organ masks
- Sequentially choose **5 distinct beam angles**
- Accumulate a **pseudo-physical dose surrogate** over timesteps
- Optimize reward balancing:
  - **PTV coverage** (good)
  - **OAR sparing** (avoid toxicity)

Inference time: **<1 second** per patient.


---

## ðŸ“ Repository Structure

```
Deep-Reinforcement-Learning-for-Personalized-Radiotherapy-Beam-Orientation-Optimization/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ experiments.json
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ success_cases/      # Best examples
â”‚   â”œâ”€â”€ typical_cases/      # Typical
â”‚   â”œâ”€â”€ failure_cases/     # Failure cases
â”‚   â””â”€â”€ anomaly_cases/     # Special discussion
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_dqn_model.pt
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ summary_results.md
â”‚   â””â”€â”€ test_results.csv
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ repro.py
â”œâ”€â”€ baselines.py
â”œâ”€â”€ eval_main.py
â”œâ”€â”€ train.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## âš™ï¸ Installation

```bash
git clone https://github.com/krishdef7/Deep-Reinforcement-Learning-for-Personalized-Radiotherapy-Beam-Orientation-Optimization.git
cd Deep-Reinforcement-Learning-for-Personalized-Radiotherapy-Beam-Orientation-Optimization
pip install -r requirements.txt
```


---

## ðŸ“‚ Dataset (OpenKBP)

We use the OpenKBP dataset (head-and-neck):

- CT volumes  
- PTV mask  
- OAR masks (cord, brainstem, L/R parotids, mandible)

Split:

- Train: **200**
- Validation: **40**
- Test: **100**

ðŸ›  Users must download OpenKBP separately and update paths in `configs/experiments.json`


---

## â–¶ï¸ Running Evaluation (Generate Results + Figures)

```bash
python eval_main.py
```

Outputs will include:

- `results/test_results.csv` â€” per-patient metrics (D95, coverage, OAR doses)
- `figures/patient_XXX_dose_dqn.png` â€” DQN dose maps overlaid on CT
- `figures/patient_XXX_dvh_dqn.png` â€” doseâ€“volume histogram plots


---

## ðŸ‹ï¸ Training from Scratch

```bash
python train.py
```

Training summary:

- Replay buffer: 3000
- Batch size: 32
- Î³ = 0.95
- Îµ-greedy: 0.90 â†’ 0.10
- Target network update every 5 epochs
- Converges in ~3.5 hours CPU


---

## ðŸ“ˆ Results â€” 100 Patient Evaluation

| Method        | Coverage  | D95     |
|--------------|-----------|---------|
| **DQN (ours)** | **0.8059** | **0.2405** |
| Equiangular   | 0.6867    | 0.1207 |
| Heuristic     | 0.6397    | 0.0949 |
| RandomMean    | 0.5883    | 0.0554 |

### Key Highlights
- **+11.9% absolute improvement** in PTV coverage
- **~2Ã— improvement** in D95
- **<1 second** per patient (post-training)
- Strong generalization across **100 unseen CT cases**


---

## ðŸ§¬ Model Summary

**State (8 channels):**
- CT
- PTV mask
- 5 OAR masks
- Accumulating dose surrogate

**Actions:**
- 36 discrete gantry angles (0â€“350Â° at 10Â° spacing)
- DQN selects **5 sequential non-repeating beams**

**Architecture:**
- 5Ã— Conv layers + BN + ReLU
- Bottleneck: 4Ã—4Ã—256
- Fully connected head
- Masking to prevent repeated beams
- Model parameters: ~3.4M

**Dose Surrogate:**
1) Ray-traced geometric field  
2) Gaussian blur â†’ approximate scatter  
3) Accumulate dose per timestep  

**Reward:**
- Terminal reward based on:
  - â†‘ D95 and coverage
  - â†“ mean OAR dose


---

## ðŸŽ¨ Qualitative Examples

Located in:

```
figures/success_cases/
figures/typical_cases/
figures/failure_cases/
figures/anomaly_cases/
```

High-dose regions remain **inside PTV** and spare critical OARs.  
DVH curves reflect improved target coverage.


---

## ðŸ“Š Baselines Implemented

All evaluated under **identical surrogate dose** to ensure fair comparison:

- **Equiangular beams**
- **Geometry heuristic**
- **Random non-repeating beams** (mean)


---

## ðŸ§­ Clinical Interpretation

- Higher D95 â†’ higher local tumor control likelihood
- OAR avoidance reduces severe toxicity risk
- <1s runtime enables:
  - Adaptive planning
  - Online replanning
  - QA workflow assistive tools


---

## ðŸš§ Limitations (Honest Assessment)

- Surrogate dose â‰  true Monte Carlo dose
- Current version operates on **single 2D slice**
- Trained only on **head-and-neck geometry**
- Research prototype â€” **not clinically deployable**


---

## ðŸ”® Future Directions

- 3D DQN / U-Net encoders
- GPU-based Monte Carlo integration
- Learned neural surrogate physics
- Multi-objective RL (Pareto optimal)
- Online robustness against anatomical changes
- Multi-disease training (lung, pelvis, liver)


---

## ðŸ“„ Citation

If you use this repository, please cite:

**Deep Reinforcement Learning for Personalized Radiotherapy Beam Orientation Optimization.  
Krish Garg, IIT Roorkee, 2025.**


---

## ðŸ™ Acknowledgements

- OpenKBP dataset contributors
- IIT Roorkee â€” Department of Physics (institutional affiliation)
- No external funding used

